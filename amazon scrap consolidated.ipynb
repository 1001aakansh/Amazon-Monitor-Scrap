{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import codecs\n",
    "import pdb\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a variable which stores working diectory and one which stores the path where the webpagess needeth to be dumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=os.getcwd()\n",
    "webpage_dump = directory + \"\\\\webpages\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading the webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing Chrome Webdriver and opening the url with the search term.\n",
    "driver=webdriver.Chrome()\n",
    "url=\"https://www.amazon.in/s?k=monitors&crid=IBS3D4BWHX6M&qid=1675433952&sprefix=monitors%2Caps%2C240&ref=sr_pg_1\"\n",
    "driver.get(url)\n",
    "#Finding the total number of webpages \n",
    "soup=BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "page_number=soup.find_all(class_=\"s-pagination-strip\")[0].text\n",
    "Nfinder=page_number.find(\"N\")\n",
    "Page=page_number[Nfinder-2] + page_number[Nfinder-1]\n",
    "Page=Page.strip(\".\")\n",
    "Page_count=int(Page)\n",
    "#running a loop with stop condition as total number of pages and then iterating through the pages and downloading them\n",
    "for i in range(1,Page_count+1):\n",
    "    url=f\"https://www.amazon.in/s?k=monitors&page={i}&crid=IBS3D4BWHX6M&qid=1675433952&sprefix=monitors%2Caps%2C240&ref=sr_pg_{i}\"\n",
    "    driver.get(url)\n",
    "    a=os.path.join(webpage_dump, f\"{i}.html\")\n",
    "    b=codecs.open(a, \"w\", \"utf-8\")\n",
    "    c=driver.page_source\n",
    "    b.write(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parsing the HTML and saving details to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing lists\n",
    "Original_Price=[]\n",
    "Renewed=[]\n",
    "Discount=[]\n",
    "Discount_Percentage=[]\n",
    "Discounted_Price=[]\n",
    "Company_Name=[]\n",
    "Average_Rating=[]\n",
    "Ratings_Count=[]\n",
    "Model_Number=[]\n",
    "Delivery_Date=[]\n",
    "Screen_Size=[]\n",
    "Resolution=[]\n",
    "resolution_numbers=[\"1080\", \"1440\", \"2160\", \"1366\", \"1280\", \"1600\"]\n",
    "resolution_text=[\"FHD\", \"QHD\", \"UHD\", \"5K\", \"HD\"]\n",
    "resolution=[\"FHD\", \"2K\", \"4K\", \"5K\"]\n",
    "Additional_Details=[]\n",
    "\n",
    "\n",
    "\n",
    "#finding total number of pages\n",
    "with open(f\"{webpage_dump}\\\\{1}.html\", \"r\", encoding=\"UTF-8\") as reader:\n",
    "    html_string=reader.read()\n",
    "    soup=BeautifulSoup(html_string, 'html.parser')\n",
    "page_number=soup.find_all(class_=\"s-pagination-strip\")[0].text\n",
    "Nfinder=page_number.find(\"N\")\n",
    "Page=page_number[Nfinder-2] + page_number[Nfinder-1]\n",
    "Page=Page.strip(\".\")\n",
    "Page_count=int(Page)\n",
    "\n",
    "\n",
    "#starting the loop with stop condition as the total number of pages\n",
    "for z in range(1,Page_count+1):\n",
    "    print(f\"Page Number{z} Processing: \\n\")\n",
    "    with open(f\"{webpage_dump}\\\\{z}.html\", \"r\", encoding=\"UTF-8\") as reader:\n",
    "        html_string=reader.read()\n",
    "        soup=BeautifulSoup(html_string, 'html.parser')\n",
    "    d=soup.find_all(class_=\"a-section a-spacing-small a-spacing-top-small\")[0].text\n",
    "    d=d.strip(\"\\n\")\n",
    "    e=d.split(\"-\")\n",
    "    master_result=e[1].split(\" \")\n",
    "    f=int(master_result[0])-int(e[0]) #number of sponsored listings\n",
    "    w=f \n",
    "    count=0 #number of unsponsored listings\n",
    "\n",
    "\n",
    "    for i in range(w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[i].text\n",
    "        if \"Sponsored\" in f:\n",
    "            count+=1\n",
    "    w=w+count\n",
    "    w=w+1\n",
    "\n",
    "\n",
    "\n",
    "    #Computing Company Name\n",
    "    for i in range(w):\n",
    "        d=soup.find_all(class_=\"a-size-medium a-color-base a-text-normal\")[i].text\n",
    "        d=d.split(\" \")\n",
    "        if (d[0]==\"Renewed\"):\n",
    "            Company_Name.append(d[1])\n",
    "        else:\n",
    "            Company_Name.append(d[0])\n",
    "\n",
    "\n",
    "\n",
    "    #Computing Resolution\n",
    "    for i in range(w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[i].text\n",
    "        f=f.strip(\"SponsoredSponsored You are seeing this ad based on the product’s relevance to your search query.Let us know\")\n",
    "        if resolution[0] in f:\n",
    "            Resolution.append(resolution_text[0])\n",
    "        elif resolution[1] in f:\n",
    "            Resolution.append(resolution_text[1])\n",
    "        elif resolution[2] in f:\n",
    "            Resolution.append(resolution_text[2])\n",
    "        elif resolution_numbers[0] in f:\n",
    "            Resolution.append(resolution_text[0])\n",
    "        elif resolution_numbers[1] in f:\n",
    "            Resolution.append(resolution_text[1])\n",
    "        elif resolution_numbers[2] in f:\n",
    "            Resolution.append(resolution_text[2])\n",
    "        elif resolution_text[0] in f:\n",
    "            Resolution.append(resolution_text[0])\n",
    "        elif resolution_text[1] in f:\n",
    "            Resolution.append(resolution_text[1])\n",
    "        elif resolution_text[2] in f:\n",
    "            Resolution.append(resolution_text[2])\n",
    "        elif resolution_text[3] in f:\n",
    "            Resolution.append(resolution_text[3])\n",
    "        elif resolution_numbers[3] in f:\n",
    "            Resolution.append(resolution_text[4])\n",
    "        elif resolution_numbers[4] in f:\n",
    "            Resolution.append(resolution_text[4])\n",
    "        elif resolution_numbers[5] in f:\n",
    "            Resolution.append(resolution_text[4])\n",
    "        else:\n",
    "            Resolution.append(np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Computing Prices\n",
    "    x=0\n",
    "    y=0\n",
    "    while(x!=w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[x].text\n",
    "        f=f.strip(\"SponsoredSponsored You are seeing this ad based on the product’s relevance to your search query.Let us know\")\n",
    "        if (\"₹\") in f:\n",
    "            d=soup.find_all(class_=\"a-row a-size-base a-color-base\")[y].text\n",
    "            d=d.split(\"₹\")\n",
    "            \n",
    "            g=d[1].replace(\",\", \"\")\n",
    "            if (len(d)<4):\n",
    "                Discount_Percentage.append(np.nan)\n",
    "                Discount.append(np.nan)\n",
    "                Discounted_Price.append(np.nan)\n",
    "                Original_Price.append(float(g))\n",
    "                h=float(e)\n",
    "            else:\n",
    "                e=d[3].replace(\",\", \"\")\n",
    "                Discounted_Price.append(float(g))\n",
    "                h=float(e)\n",
    "                k=float(g)\n",
    "                Original_Price.append(float(e)) \n",
    "                \n",
    "                \n",
    "                Discount.append(h-k)\n",
    "                Discount_Percentage.append(int(((h-k)/h)*100))\n",
    "            y+=1       \n",
    "        else:\n",
    "            Original_Price.append(np.nan)\n",
    "            Discount.append(np.nan)\n",
    "            Discount_Percentage.append(np.nan)\n",
    "            Discounted_Price.append(np.nan)\n",
    "        x+=1 \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Computing Reviews\n",
    "    x=0\n",
    "    y=0\n",
    "    while(x!=w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[x].text\n",
    "        f=f.strip(\"SponsoredSponsored You are seeing this ad based on the product’s relevance to your search query.Let us know\")\n",
    "        try:\n",
    "            if \"out of 5 stars\" in f:\n",
    "                d=soup.find_all(class_=\"a-row a-size-small\")[y].text\n",
    "                d=d.split(\" \")\n",
    "                Average_Rating.append(float(d[0]))\n",
    "                if (len(d[5])>3):\n",
    "                    e=d[5].split(\",\")\n",
    "                    Ratings_Count.append(int(e[0]+e[1]))\n",
    "                else:\n",
    "                    Ratings_Count.append(int(d[5]))\n",
    "                y+=1\n",
    "            else:\n",
    "                Average_Rating.append(np.nan)\n",
    "                Ratings_Count.append(np.nan)\n",
    "            x+=1\n",
    "        except IndexError:\n",
    "            continue\n",
    "    #Computing Model Number\n",
    "    for i in range(w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[i].text\n",
    "        f=f.strip(\"SponsoredSponsored You are seeing this ad based on the product’s relevance to your search query.Let us know\")\n",
    "        e=f.split(\" \")\n",
    "        Model_Number.append(e[1])\n",
    "\n",
    "\n",
    "    #Computing Delivery Date\n",
    "    x=0\n",
    "    y=0\n",
    "    months=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "    month_number=[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "    while (x!=w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[x].text\n",
    "        if 'Get' in f:\n",
    "            d=soup.find_all(class_=\"a-color-base a-text-bold\")[y].text\n",
    "            d=d.split(\",\")\n",
    "            e=d[1].split(\" \")\n",
    "            g=months.index(e[1])\n",
    "            \n",
    "            if len(e[2])==1:\n",
    "                h=\"0\"+e[2]\n",
    "                k=f\"2023-{month_number[g]}-{h}\"  \n",
    "            else:\n",
    "                h=e[2]\n",
    "                k=f\"2023-{month_number[g]}-{h}\"\n",
    "            Delivery_Date.append(k)\n",
    "            y+=1\n",
    "        \n",
    "        else:\n",
    "            Delivery_Date.append(np.nan)\n",
    "        x+=1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #Computing all other details\n",
    "    for i in range(w):\n",
    "        f=soup.find_all(class_=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\")[i].text\n",
    "        Additional_Details.append(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Computing Renewed Products\n",
    "    for i in range(w):\n",
    "        f=soup.find_all(class_=\"sg-col sg-col-4-of-12 sg-col-8-of-16 sg-col-12-of-20 s-list-col-right\")[i].text\n",
    "        if \"(Renewed)\" in f:\n",
    "            Renewed.append(\"Yes\")\n",
    "        else:\n",
    "            Renewed.append(np.nan)\n",
    "df=pd.DataFrame({\"Company_Name\": Company_Name, \"Model_Number\": Model_Number, \"Resolution\": Resolution, \"Original_Price\": Original_Price, \"Discount\": Discount, \"Discount_Percentage\": Discount_Percentage, \"Discounted_Price\": Discounted_Price, \"Average_Rating\": Average_Rating, \"Ratings_Count\": Ratings_Count, \"Delivery_Date\": Delivery_Date, \"Renewed_Staus\": Renewed, \"Additional_Details\": Additional_Details})\n",
    "df.to_excel(\"Amazon Monitor Scrap.xlsx\", sheet_name=\"1\")    \n",
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
